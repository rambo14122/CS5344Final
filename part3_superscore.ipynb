{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part3 Superscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "## Importing Basic Packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Import NLP Packages\n",
    "import re\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# NLTK Stop words\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come'])\n",
    "\n",
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config('spark.driver.memory', '8g').config('spark.executor.memory','8g').config('spark.driver.maxResultSize','0').config('spark.sql.autoBroadcastJoinThreshold','-1').config('spark.sql.broadcastTimeout','1200').config('spark.default.parallelism','8').appName(\"superscore\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8976/796850429.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'part1_dataclean_review.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mreview\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultiLine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\IDE\\Conda3\\envs\\CS5344V3\\lib\\site-packages\\pyspark\\sql\\readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[1;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[0;32m    735\u001b[0m             \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 737\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    738\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\IDE\\Conda3\\envs\\CS5344V3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1308\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1310\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1312\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\IDE\\Conda3\\envs\\CS5344V3\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: Path does not exist: file:/E:/courses/part1_dataclean_review.csv"
     ],
     "ename": "AnalysisException",
     "evalue": "Path does not exist: file:/E:/courses/part1_dataclean_review.csv",
     "output_type": "error"
    }
   ],
   "source": [
    "path = 'part1_dataclean_review.csv'\n",
    "review = spark.read.csv(path, header=True, multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "review.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "review.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "review.select(['text']).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Reviews Forsight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "neg_reviews = review.filter(review.stars <= 2.5)  # reviews with star <= 2.5\n",
    "print(neg_reviews.count(), len(neg_reviews.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "neg_reviews.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer, StopWordsRemover, RegexTokenizer\n",
    "\n",
    "neg_reviews_text = neg_reviews.select(['text'])\n",
    "\n",
    "tokenizer = RegexTokenizer().setInputCol(\"text\").setOutputCol(\"words\").setPattern(\"\\\\W\")\n",
    "wordsData = tokenizer.transform(neg_reviews_text)\n",
    "\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "filter_data = remover.transform(wordsData)\n",
    "\n",
    "\n",
    "cv = CountVectorizer(inputCol='filtered', outputCol='vectors')\n",
    "model = cv.fit(filter_data)\n",
    "\n",
    "counts = model.transform(filter_data).select(['filtered','vectors'])\n",
    "\n",
    "neg_words_top10 = counts.select('vectors', explode(\"filtered\").alias(\"word\")).groupBy(\"word\").count()\n",
    "neg_words_top10 = neg_words_top10.sort(\"count\", ascending=False)\n",
    "neg_words_top10.show(10) # list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Remove non-informative words\n",
    "tokenizer = RegexTokenizer().setInputCol(\"text\").setOutputCol(\"words\").setPattern(\"\\\\W\")\n",
    "wordsData = tokenizer.transform(neg_reviews_text)\n",
    "\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "filter_data = remover.transform(wordsData)\n",
    "\n",
    "\n",
    "cv = CountVectorizer(inputCol='filtered', outputCol='vectors',minDF=2.0, vocabSize=1000)\n",
    "model = cv.fit(filter_data)\n",
    "\n",
    "counts = model.transform(filter_data).select(['filtered','vectors'])\n",
    "\n",
    "non_informative_words = ['food', 'place', 'like', 'service','good','one','get','time','back','us']\n",
    "\n",
    "neg_words_top150 = counts.select('vectors', explode(\"filtered\").alias(\"word\")).where(col(\"word\").isin(non_informative_words)==False).groupBy(\"word\").count()\n",
    "neg_words_top150 = neg_words_top150.sort(\"count\", ascending=False)\n",
    "neg_words_top150 = neg_words_top150.select(['word']).take(150) # list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "neg_words_top150_list = []\n",
    "for nwt150 in neg_words_top150:\n",
    "    if nwt150['word'].isnumeric():\n",
    "        continue\n",
    "    neg_words_top150_list.append(nwt150['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print(neg_words_top150_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "wordcloud_low = WordCloud(background_color=\"white\").generate(' '.join(neg_words_top150_list))\n",
    "plt.figure(figsize = (12,10))\n",
    "plt.imshow(wordcloud_low, interpolation='bilinear')\n",
    "plt.title('Word Cloud - Negative Yelp Restaurant Reviews', fontsize=16, y=1.01)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive Reviews Forsight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "pos_reviews = review.filter(review.stars >= 4.5)  # reviews with star >= 4.5\n",
    "print(pos_reviews.count(), len(pos_reviews.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "pos_reviews.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "pos_reviews_text = pos_reviews.select(['text'])\n",
    "\n",
    "tokenizer = RegexTokenizer().setInputCol(\"text\").setOutputCol(\"words\").setPattern(\"\\\\W\")\n",
    "wordsData = tokenizer.transform(pos_reviews_text)\n",
    "\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "filter_data = remover.transform(wordsData)\n",
    "\n",
    "\n",
    "cv = CountVectorizer(inputCol='filtered', outputCol='vectors')\n",
    "model = cv.fit(filter_data)\n",
    "\n",
    "counts = model.transform(filter_data).select(['filtered','vectors'])\n",
    "\n",
    "pos_words_top10 = counts.select('vectors', explode(\"filtered\").alias(\"word\")).groupBy(\"word\").count()\n",
    "pos_words_top10 = pos_words_top10.sort(\"count\", ascending=False)\n",
    "pos_words_top10.show(10) # list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Remove non-informative words\n",
    "tokenizer = RegexTokenizer().setInputCol(\"text\").setOutputCol(\"words\").setPattern(\"\\\\W\")\n",
    "wordsData = tokenizer.transform(pos_reviews_text)\n",
    "\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "filter_data = remover.transform(wordsData)\n",
    "\n",
    "\n",
    "cv = CountVectorizer(inputCol='filtered', outputCol='vectors',minDF=2.0, vocabSize=1000)\n",
    "model = cv.fit(filter_data)\n",
    "\n",
    "counts = model.transform(filter_data).select(['filtered','vectors'])\n",
    "\n",
    "non_informative_words = ['food', 'place', 'like', 'service','portland','one']\n",
    "\n",
    "pos_words_top150 = counts.select('vectors', explode(\"filtered\").alias(\"word\")).where(col(\"word\").isin(non_informative_words)==False).groupBy(\"word\").count()\n",
    "pos_words_top150 = pos_words_top150.sort(\"count\", ascending=False)\n",
    "pos_words_top150 = pos_words_top150.select(['word']).take(150) # list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "pos_words_top150_list = []\n",
    "for pwt150 in pos_words_top150:\n",
    "    if pwt150['word'].isnumeric():\n",
    "        continue\n",
    "    pos_words_top150_list.append(pwt150['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print(pos_words_top150_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "wordcloud_low = WordCloud(background_color=\"white\").generate(' '.join(pos_words_top150_list))\n",
    "plt.figure(figsize = (12,10))\n",
    "plt.imshow(wordcloud_low, interpolation='bilinear')\n",
    "plt.title('Word Cloud - Positive Yelp Restaurant Reviews', fontsize=16, y=1.01)\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rich Features for Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_cleaned_text(value):\n",
    "    words = re.split(\"(?:[^a-zA-Z']+)\", value.lower())\n",
    "    result = \" \"\n",
    "    result = result.join(Word(w.lower()).lemmatize() for w in words if w.lower() not in stop_words)\n",
    "    return result\n",
    "\n",
    "udfget_cleaned_text = udf(get_cleaned_text, StringType())\n",
    "review = review.withColumn(\"cleaned_text\", lit(udfget_cleaned_text(\"text\")))\n",
    "\n",
    "review.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "review.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Add columns 'polarity' and 'subjectivity'\n",
    "from textblob import TextBlob\n",
    "\n",
    "def cal_polarity(value):\n",
    "    return TextBlob(value).sentiment[0]\n",
    "\n",
    "udfcal_polarity = udf(cal_polarity, DoubleType())\n",
    "review = review.withColumn(\"polarity\", lit(udfcal_polarity(\"cleaned_text\")))\n",
    "\n",
    "def cal_subjectivity(value):\n",
    "    return TextBlob(value).sentiment[1]\n",
    "\n",
    "udfcal_subjectivity = udf(cal_subjectivity, DoubleType())\n",
    "review = review.withColumn(\"subjectivity\", lit(udfcal_subjectivity(\"cleaned_text\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vader Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Calculate Vader Sentiment Analysis Scores\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def cal_compound(value):\n",
    "    return analyzer.polarity_scores(value)['compound']\n",
    "\n",
    "udfcal_compound = udf(cal_compound, DoubleType())\n",
    "review = review.withColumn(\"compound\", lit(udfcal_compound(\"text\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Superscore Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "review = review.withColumn('superscore',review['stars']+(review['polarity']*review['subjectivity']*review['compound']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "review.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "review.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print(review.count(), len(review.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "review.coalesce(1).write.option(\"header\",True).csv(\"part3_superscore_review.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-cb58f220",
   "language": "python",
   "display_name": "PyCharm (Final)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}