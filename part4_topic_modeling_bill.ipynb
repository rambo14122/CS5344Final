{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Part 4 Topic Modeling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from operator import add\n",
    "from pyspark.ml.clustering import LDA, LocalLDAModel\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from wordcloud import WordCloud\n",
    "import numpy as np\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "    .config(\"spark.driver.memory\", \"32g\")\\\n",
    "    .config(\"spark.executor.memory\",\"32g\")\\\n",
    "    .config(\"spark.driver.maxResultSize\",\"0\")\\\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\",\"-1\")\\\n",
    "    .config(\"spark.sql.broadcastTimeout\",\"1200\")\\\n",
    "    .config(\"spark.default.parallelism\", \"180\")\\\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"3600\")\\\n",
    "    .appName(\"part4\").getOrCreate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "business = spark.read.json(\"yelp_academic_dataset_business.json\")\n",
    "review = spark.read.json(\"yelp_academic_dataset_review.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Join Review Text by Business ID"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# filter review by year\n",
    "review = review.withColumn(\"year\", substring(\"date\",1,4).astype(\"int\"))\n",
    "review = review.filter(review.year>2010)\n",
    "\n",
    "# convert rdd to df\n",
    "reviews_text_rdd = review.select(\"business_id\", \"text\").rdd\n",
    "reviews_by_business_rdd = reviews_text_rdd.map(tuple).reduceByKey(add)  \n",
    "reviews_by_business_df = spark.createDataFrame(reviews_by_business_rdd)\n",
    "reviews_by_business_df = reviews_by_business_df \\\n",
    "                            .withColumnRenamed(\"_1\", \"business_id\") \\\n",
    "                            .withColumnRenamed(\"_2\", \"text\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Text Processing\n",
    "- Tokenize\n",
    "- Remove Stopwords\n",
    "- IDF\n",
    "- Word2Vector\n",
    "- Topic Modeling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "+--------------------+--------------------+--------------------+\n|         business_id|                text|               token|\n+--------------------+--------------------+--------------------+\n|Irp5sgl7XASH5ZTw2...|Enjoyed the food,...|[enjoyed, the, fo...|\n|39vR4dh70QwBqoY-Q...|Absolutely overpr...|[absolutely, over...|\n|J44x_m383C2GWtzj6...|This place is an ...|[this, place, is,...|\n+--------------------+--------------------+--------------------+\nonly showing top 3 rows\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# tokenize\n",
    "\n",
    "regex_tokenizer = RegexTokenizer(gaps = False, pattern = \"\\w+\", inputCol = \"text\", outputCol = \"token\")\n",
    "reviews_by_business_token_df = regex_tokenizer.transform(reviews_by_business_df)\n",
    "reviews_by_business_token_df.show(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n|         business_id|                text|               token|       non_stop_word|\n+--------------------+--------------------+--------------------+--------------------+\n|Irp5sgl7XASH5ZTw2...|Enjoyed the food,...|[enjoyed, the, fo...|[enjoyed, food, m...|\n|39vR4dh70QwBqoY-Q...|Absolutely overpr...|[absolutely, over...|[absolutely, over...|\n|J44x_m383C2GWtzj6...|This place is an ...|[this, place, is,...|[place, interesti...|\n+--------------------+--------------------+--------------------+--------------------+\nonly showing top 3 rows\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# remove Stopwords\n",
    "\n",
    "stopWordsRemover = StopWordsRemover(inputCol = \"token\", outputCol = \"non_stop_word\")\n",
    "reviews_by_business_token_non_stop_word_df = stopWordsRemover.transform(reviews_by_business_token_df)\n",
    "reviews_by_business_token_non_stop_word_df.show(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n|         business_id|                text|               token|       non_stop_word|         raw_feature|\n+--------------------+--------------------+--------------------+--------------------+--------------------+\n|Irp5sgl7XASH5ZTw2...|Enjoyed the food,...|[enjoyed, the, fo...|[enjoyed, food, m...|(262144,[0,1,2,3,...|\n|39vR4dh70QwBqoY-Q...|Absolutely overpr...|[absolutely, over...|[absolutely, over...|(262144,[5,10,12,...|\n|J44x_m383C2GWtzj6...|This place is an ...|[this, place, is,...|[place, interesti...|(262144,[0,1,2,3,...|\n+--------------------+--------------------+--------------------+--------------------+--------------------+\nonly showing top 3 rows\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# create feature vectors\n",
    "\n",
    "count_vectorizer = CountVectorizer(inputCol=\"non_stop_word\", outputCol=\"raw_feature\")\n",
    "cv_model = count_vectorizer.fit(reviews_by_business_token_non_stop_word_df)\n",
    "\n",
    "# save all words\n",
    "all_words = cv_model.vocabulary\n",
    "\n",
    "# show result\n",
    "reviews_featurized_df = cv_model.transform(reviews_by_business_token_non_stop_word_df)\n",
    "reviews_featurized_df.show(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n|         business_id|                text|               token|       non_stop_word|         raw_feature|          idf_vector|\n+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n|Irp5sgl7XASH5ZTw2...|Enjoyed the food,...|[enjoyed, the, fo...|[enjoyed, food, m...|(262144,[0,1,2,3,...|(262144,[0,1,2,3,...|\n|39vR4dh70QwBqoY-Q...|Absolutely overpr...|[absolutely, over...|[absolutely, over...|(262144,[5,10,12,...|(262144,[5,10,12,...|\n|J44x_m383C2GWtzj6...|This place is an ...|[this, place, is,...|[place, interesti...|(262144,[0,1,2,3,...|(262144,[0,1,2,3,...|\n+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\nonly showing top 3 rows\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# create features using IDF\n",
    "\n",
    "idf = IDF(inputCol=\"raw_feature\", outputCol=\"idf_vector\")\n",
    "idf_model = idf.fit(reviews_featurized_df)\n",
    "reviews_rescaled_df = idf_model.transform(reviews_featurized_df) \n",
    "reviews_rescaled_df.show(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word2Vec Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11824/837549952.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mword_2_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectorSize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminCount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputCol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"non_stop_word\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputCol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"word_vector\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mword_2_vector_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_2_vector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreviews_rescaled_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# save the word2vec model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\IDE\\Conda3\\envs\\CS5344V3\\lib\\site-packages\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    159\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[1;32mE:\\IDE\\Conda3\\envs\\CS5344V3\\lib\\site-packages\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m         \u001b[0mjava_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\IDE\\Conda3\\envs\\CS5344V3\\lib\\site-packages\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \"\"\"\n\u001b[0;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\IDE\\Conda3\\envs\\CS5344V3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1308\u001b[1;33m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1309\u001b[0m         return_value = get_return_value(\n\u001b[0;32m   1310\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[1;32mE:\\IDE\\Conda3\\envs\\CS5344V3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command, retry, binary)\u001b[0m\n\u001b[0;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1037\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1038\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1039\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\IDE\\Conda3\\envs\\CS5344V3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command)\u001b[0m\n\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1205\u001b[1;33m             \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1206\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Answer received: {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1207\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\IDE\\Conda3\\envs\\CS5344V3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "start building Word2Vec model\n",
      "end building Word2Vec model\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# create features using Word2Vec\n",
    "\"\"\"\n",
    "print(\"start building Word2Vec model\")\n",
    "word_2_vector = Word2Vec(vectorSize = 100, minCount = 5, \n",
    "                         numPartitions=10,\n",
    "                         inputCol = \"non_stop_word\", outputCol = \"word_vector\")\n",
    "word_2_vector_model = word_2_vector.fit(reviews_rescaled_df)\n",
    "\n",
    "# save the Word2Vec model\n",
    "\n",
    "word_2_vector_model.write().overwrite().save(\"word_2_vector_model\")\n",
    "print(\"end building Word2Vec model\")\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n|         business_id|                text|               token|       non_stop_word|         raw_feature|          idf_vector|         word_vector|\n+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n|Irp5sgl7XASH5ZTw2...|Enjoyed the food,...|[enjoyed, the, fo...|[enjoyed, food, m...|(262144,[0,1,2,3,...|(262144,[0,1,2,3,...|[0.02270535124461...|\n|39vR4dh70QwBqoY-Q...|Absolutely overpr...|[absolutely, over...|[absolutely, over...|(262144,[5,10,12,...|(262144,[5,10,12,...|[-0.0736666149279...|\n|J44x_m383C2GWtzj6...|This place is an ...|[this, place, is,...|[place, interesti...|(262144,[0,1,2,3,...|(262144,[0,1,2,3,...|[0.00487508992722...|\n+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\nonly showing top 3 rows\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# load Word2Vec model\n",
    "\n",
    "word_2_vector_model = Word2VecModel.load(\"word_2_vector_model\")\n",
    "reviews_vector_df = word_2_vector_model.transform(reviews_rescaled_df)\n",
    "reviews_vector_df.show(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "chinese\n+------------+------------------+\n|        word|        similarity|\n+------------+------------------+\n|   cantonese|0.8301430940628052|\n|   taiwanese|0.8289218544960022|\n|shanghainese|0.8207446932792664|\n|americanized|0.7875234484672546|\n|    filipino|0.7843402624130249|\n+------------+------------------+\n\nwestern\n+------------+------------------+\n|        word|        similarity|\n+------------+------------------+\n|    american|0.7176516056060791|\n|southeastern|0.6309979557991028|\n|  hemisphere|0.6186148524284363|\n|    northern|0.6179028749465942|\n|        fare| 0.601344108581543|\n+------------+------------------+\n\nseafood\n+-----------+------------------+\n|       word|        similarity|\n+-----------+------------------+\n|   cioppino|0.7607556581497192|\n|      clams| 0.743668794631958|\n|   seafoods|0.7104874849319458|\n|spaghettoni|0.7079223394393921|\n|    newburg| 0.704081118106842|\n+-----------+------------------+\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# test Word2Vec model\n",
    "print(\"chinese\")\n",
    "\n",
    "word_2_vector_model.findSynonyms(\"chinese\", 5).show()\n",
    "\n",
    "print(\"western\")\n",
    "word_2_vector_model.findSynonyms(\"western\", 5).show()\n",
    "\n",
    "print(\"seafood\")\n",
    "word_2_vector_model.findSynonyms(\"seafood\", 5).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Topic Modeling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "start building LDA model\n",
      "end building LDA model\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# build lda model\n",
    "\"\"\"\n",
    "print(\"start building LDA model\")\n",
    "lda = LDA(k=10, seed=1, optimizer=\"online\", featuresCol=\"idf_vector\")\n",
    "lda_model = lda.fit(reviews_rescaled_df)\n",
    "\n",
    "# save lda model\n",
    "\n",
    "lda_model.write().overwrite().save(\"lda_model\")\n",
    "print(\"end building LDA model\")\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "####################\ntopic 0:  food cupcakes gyro falafel lamb pita greek cupcake hummus chicken\n####################\ntopic 1:  hair burger beer dog haircut vet salon store stylist burgers\n####################\ntopic 2:  pho thai food chicken pad vietnamese shrimp fried grits biscuit\n####################\ntopic 3:  car nails massage nail salon pedicure appointment company manicure vehicle\n####################\ntopic 4:  hotel disney room park rooms tour pool ride dress stay\n####################\ntopic 5:  dr gym classes dentist class dental doctor yoga studio workout\n####################\ntopic 6:  pizza tacos food taco bar mexican wings salsa cheese drinks\n####################\ntopic 7:  ramen donuts indian donut naan doughnuts voodoo food masala doughnut\n####################\ntopic 8:  food coffee delicious menu restaurant breakfast sandwich brunch cheese cream\n####################\ntopic 9:  sushi food chicken rice pork restaurant fried sauce bbq menu\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# load the LDA_model\n",
    "\n",
    "lda_model = LocalLDAModel.load(\"lda_model\")\n",
    "\n",
    "topics = lda_model.describeTopics()\n",
    "topics_words = topics.rdd\\\n",
    "       .map(lambda row: row[\"termIndices\"])\\\n",
    "       .map(lambda idx_list: [all_words[i] for i in idx_list])\\\n",
    "       .collect()\n",
    "\n",
    "for idx, topic in enumerate(topics_words):\n",
    "    print(\"####################\")\n",
    "    topic_words = \"\"\n",
    "    for word in topic:\n",
    "        topic_words = topic_words + \" \" + word\n",
    "    print(\"topic \"+ str(idx) + \": \" + topic_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+\n|         business_id|                text|               token|       non_stop_word|         raw_feature|          idf_vector|         word_vector|token_count|\n+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+\n|Irp5sgl7XASH5ZTw2...|Enjoyed the food,...|[enjoyed, the, fo...|[enjoyed, food, m...|(262144,[0,1,2,3,...|(262144,[0,1,2,3,...|[0.02270535124461...|      18024|\n|39vR4dh70QwBqoY-Q...|Absolutely overpr...|[absolutely, over...|[absolutely, over...|(262144,[5,10,12,...|(262144,[5,10,12,...|[-0.0736666149279...|        233|\n|J44x_m383C2GWtzj6...|This place is an ...|[this, place, is,...|[place, interesti...|(262144,[0,1,2,3,...|(262144,[0,1,2,3,...|[0.00487508992722...|       8524|\n+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+\nonly showing top 3 rows\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# add the token count \n",
    "\n",
    "token_len = udf(lambda s: len(s), IntegerType())\n",
    "reviews_vector_df = reviews_vector_df.withColumn(\"token_count\", token_len(reviews_vector_df.non_stop_word))\n",
    "reviews_vector_df.show(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8896/1023371186.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# create a business summary for more analysis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreviews_vector_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"business_id\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"idf_vector\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"word_vector\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"non_stop_word\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malias\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"a\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbusiness\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"business_id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"name\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"categories\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"review_count\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malias\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"b\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reviews_vector_df' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'reviews_vector_df' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "# create a business summary for more analysis\n",
    "\n",
    "a = reviews_vector_df.select(\"business_id\",\"idf_vector\", \"word_vector\", \"non_stop_word\").alias(\"a\")\n",
    "b = business.select(\"business_id\", \"name\", \"categories\", \"review_count\").alias(\"b\")\n",
    "\n",
    "summary = a.join(b, col(\"a.business_id\") == col(\"b.business_id\"), \"inner\") \n",
    "summary.show(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word Cloud Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# prepare for generating word cloud\n",
    "\n",
    "def word_cloud(text):\n",
    "    wc = WordCloud().generate(text)\n",
    "    plt.imshow(wc)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "summary.select(\"business_id\", \"business_name\", \"categories\") \\\n",
    "        .filter((summary.stars == 5) & (summary.review_count > 30)) \\\n",
    "        .show(5, truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test word cloud\n",
    "\n",
    "bid = \"J9vAdD2dCpFuGsxPIn184w\"\n",
    "all_reviews = \"\".join(summary.select(\"non_stop_word\").filter(summary.business_id == bid).rdd.take(1)[0][0])\n",
    "word_cloud(all_reviews)\n",
    "\n",
    "\n",
    "bid = \"ixfpsy7M6vLAe0Xf-EWH4g\"\n",
    "all_reviews = \"\".join(summary.select(\"non_stop_word\").filter(summary.business_id == bid).rdd.take(1)[0][0])\n",
    "word_cloud(all_reviews)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check Similarity Score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define similarity function\n",
    "def cosine_similarity(vector1, vector2): \n",
    "    return np.dot(vector1, vector2) / np.sqrt(np.dot(vector1, vector1)) / np.sqrt(np.dot(vector2, vector2)) \n",
    "\n",
    "def check_similarity(business_id1, business_id2):\n",
    "    summary.select(\"token_count\", \"business_name\", \"categories\") \\\n",
    "        .filter(summary.business_id.isin(business_id1, business_id2)) \\\n",
    "        .show(truncate=False)\n",
    "        \n",
    "    bus_review_text1 = \" \".join(summary.select(\"non_stop_word\") \\\n",
    "                                .filter(summary.business_id == business_id1).rdd.take(1)[0][0])\n",
    "    bus_review_text2 = \" \".join(summary.select(\"non_stop_word\") \\\n",
    "                                .filter(summary.business_id == business_id2).rdd.take(1)[0][0])\n",
    "    \n",
    " \n",
    "    word_cloud(bus_review_text1)\n",
    "    word_cloud(bus_review_text2)\n",
    "    \n",
    "    # cosine similarity from IDF vectors\n",
    "    bus_vector1 = summary.select(\"idf_vector\").filter(summary.business_id == business_id1).rdd.take(1)[0][0]\n",
    "    bus_vector2 = summary.select(\"idf_vector\").filter(summary.business_id == business_id2).rdd.take(1)[0][0]\n",
    "    \n",
    "    # convert Sparse vectors to Dense vectors\n",
    "    vector1 = DenseVector(bus_vector1.toArray())\n",
    "    vector2 = DenseVector(bus_vector2.toArray())\n",
    "    print(\"cosine similarity based on IDF vectors     : \" + str(cosine_similarity(vector1, vector2)))\n",
    "    \n",
    "    # cosine similarity from Word2Vec vectors\n",
    "    vector1 = summary.select(\"word_vector\").filter(summary.business_id == business_id1).rdd.take(1)[0][0]\n",
    "    vector2 = summary.select(\"word_vector\").filter(summary.business_id == business_id2).rdd.take(1)[0][0]\n",
    "    print(\"cosine similarity based on Word2Vec vectors: \" + str(cosine_similarity(vector1, vector2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test similarity score\n",
    "# test case 1\n",
    "\n",
    "business1 = \"RtUvSWO_UZ8V3Wpj0n077w\" \n",
    "business2 = \"CN5nuUQod0f8g3oh99qq0w\"\n",
    "check_similarity(business1, business2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test case 2\n",
    "\n",
    "business1 = 'ZumOnWbstgsIE6bJlxw0_Q'\n",
    "business2 = 'JJ8ypBu3b--fy4HA5RB1gg'\n",
    "check_similarity(business1, business2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-cb58f220",
   "language": "python",
   "display_name": "PyCharm (Final)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}