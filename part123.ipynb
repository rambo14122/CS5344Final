{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "## Importing Basic Packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Import NLP Packages\n",
    "import re\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# NLTK Stop words\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config('spark.driver.memory', '16g').config('spark.executor.memory','16g').config('spark.driver.maxResultSize','0').config('spark.sql.autoBroadcastJoinThreshold','-1').config('spark.sql.broadcastTimeout','1200').config('spark.default.parallelism','8').appName(\"part123\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bussiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "160585"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "path = 'yelp_academic_dataset_business.json'\n",
    "business = spark.read.json(path)\n",
    "business.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "business_col = ['business_id','name','city','state','stars','review_count','categories','latitude','longitude','is_open', 'postal_code']\n",
    "business = business.select(business_col)\n",
    "#business = business.withColumn('category', split(business['categories'],',')).withColumn('category',explode('category')).withColumn('category', trim('category'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "+--------------------+-----+\n|            category|count|\n+--------------------+-----+\n|         Restaurants|50763|\n|                Food|29469|\n|            Shopping|26205|\n|       Beauty & Spas|16574|\n|       Home Services|16465|\n|    Health & Medical|15102|\n|      Local Services|12192|\n|           Nightlife|11990|\n|                Bars|10741|\n|          Automotive|10119|\n|Event Planning & ...| 9644|\n|         Active Life| 9231|\n|        Coffee & Tea| 7725|\n|          Sandwiches| 7272|\n|             Fashion| 6599|\n|American (Traditi...| 6541|\n|         Hair Salons| 5900|\n|               Pizza| 5756|\n|     Hotels & Travel| 5703|\n|  Breakfast & Brunch| 5505|\n+--------------------+-----+\nonly showing top 20 rows\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "tmp = business.withColumn('category', explode(split(business['categories'],','))).withColumn('category', trim('category'))\n",
    "tmp.groupBy('category').count().orderBy('count',ascending=False).show()\n",
    "#selected_category = ['Restaurants','Food','Coffee & Tea','Sandwiches','Breakfast & Brunch']\n",
    "regex_expr = r'\\b(Restaurants|Food|Coffee|Tea|Sandwiches|Breakfast|Brunch)\\b'\n",
    "business = business.filter(business['categories'].rlike(regex_expr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "64092"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 11
    }
   ],
   "source": [
    "business.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "+---------------+-----+\n|           city|count|\n+---------------+-----+\n|       Portland| 7212|\n|      Vancouver| 6495|\n|         Austin| 6373|\n|        Atlanta| 5092|\n|        Orlando| 4592|\n|         Boston| 3536|\n|       Columbus| 3164|\n|       Richmond| 1127|\n|      Cambridge|  957|\n|        Burnaby|  919|\n|        Boulder|  882|\n|      Kissimmee|  846|\n|      Beaverton|  735|\n|        Decatur|  627|\n|     Somerville|  510|\n|North Vancouver|  500|\n|    Winter Park|  495|\n|         Quincy|  414|\n|      Coquitlam|  383|\n|         Surrey|  344|\n+---------------+-----+\nonly showing top 20 rows\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "business.groupBy('city').count().orderBy('count',ascending = False).show()\n",
    "selected_city = ['Portland']\n",
    "business = business.filter(col('city').isin(selected_city))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "+-----------+----+----+-----+-----+------------+----------+--------+---------+-------+-----------+\n|business_id|name|city|state|stars|review_count|categories|latitude|longitude|is_open|postal_code|\n+-----------+----+----+-----+-----+------------+----------+--------+---------+-------+-----------+\n|          0|   0|   0|    0|    0|           0|         0|       0|        0|      0|          0|\n+-----------+----+----+-----+-----+------------+----------+--------+---------+-------+-----------+\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "business = business[business['is_open']==1]\n",
    "business.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in business.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "4127"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 14
    }
   ],
   "source": [
    "business.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "path = 'yelp_academic_dataset_review.json'\n",
    "review = spark.read.json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "8635403"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 16
    }
   ],
   "source": [
    "review.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "root\n |-- business_id: string (nullable = true)\n |-- cool: long (nullable = true)\n |-- date: string (nullable = true)\n |-- funny: long (nullable = true)\n |-- review_id: string (nullable = true)\n |-- stars: double (nullable = true)\n |-- text: string (nullable = true)\n |-- useful: long (nullable = true)\n |-- user_id: string (nullable = true)\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "review.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n|         business_id|cool|               date|funny|           review_id|stars|                text|useful|             user_id|\n+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n|buF9druCkbuXLX526...|   1|2014-10-11 03:34:02|    1|lWC-xP3rd6obsecCY...|  4.0|Apparently Prides...|     3|ak0TdVmGKo4pwqdJS...|\n|RA4V8pr014UyUbDvI...|   0|2015-07-03 20:38:25|    0|8bFej1QE5LXp4O05q...|  4.0|This store is pre...|     1|YoVfDbnISlW0f7abN...|\n|_sS2LBIGNT5NQb6PD...|   0|2013-05-28 20:38:06|    0|NDhkzczKjLshODbqD...|  5.0|I called WVM on t...|     0|eC5evKn1TWDyHCyQA...|\n|0AzLzHfOJgL7ROwhd...|   1|2010-01-08 02:29:15|    1|T5fAqjjFooT4V0OeZ...|  2.0|I've stayed at ma...|     1|SFQ1jcnGguO0LYWnb...|\n|8zehGz9jnxPqXtOc7...|   0|2011-07-28 18:05:01|    0|sjm_uUcQVxab_EeLC...|  4.0|The food is alway...|     0|0kA0PAJ8QFMeveQWH...|\n|xGXzsc-hzam-VArK6...|   0|2018-01-21 04:41:03|    0|J4a2TuhDasjn2k3wW...|  1.0|This place used t...|     2|RNm_RWkcd02Li2mKP...|\n|EXOsmAB1s71WePlQk...|   0|2006-04-16 02:58:44|    0|28gGfkLs3igtjVy61...|  2.0|The setting is pe...|     0|Q8c91v7luItVB0cMF...|\n|DbXHNl890xSXNiyRc...|   0|2017-12-02 18:16:13|    0|9vqwvFCBG3FBiHGmO...|  5.0|Probably one of t...|     0|XGkAG92TQ3MQUKGX9...|\n|mD-A9KOWADXvfrZfw...|   0|2012-05-28 15:00:47|    0|2l_TDrQ7p-5tANOyi...|  4.0|I am definitely a...|     1|LWUnzwK0ILquLLZcH...|\n|EEHhKSxUvJkoPSzeG...|   0|2014-05-07 18:10:21|    0|KKVFopqzcVfcubIBx...|  5.0|I work in the Pru...|     0|99RsBrARhhx60UnAC...|\n+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\nonly showing top 10 rows\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "review.show(10)\n",
    "review = review.withColumn('year', substring('date',1,4).astype('int'))\n",
    "review = review.withColumn('month', substring('date',6,2).astype('int'))\n",
    "review = review.withColumn('day', substring('date',9,2).astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "review_col = ['review_id','business_id','user_id','year','month','day','stars','useful','funny','cool','text']\n",
    "review = review.select(review_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "+--------------------+--------------------+--------------------+----+-----+---+-----+------+-----+----+--------------------+\n|           review_id|         business_id|             user_id|year|month|day|stars|useful|funny|cool|                text|\n+--------------------+--------------------+--------------------+----+-----+---+-----+------+-----+----+--------------------+\n|lWC-xP3rd6obsecCY...|buF9druCkbuXLX526...|ak0TdVmGKo4pwqdJS...|2014|   10| 11|  4.0|     3|    1|   1|Apparently Prides...|\n|8bFej1QE5LXp4O05q...|RA4V8pr014UyUbDvI...|YoVfDbnISlW0f7abN...|2015|    7|  3|  4.0|     1|    0|   0|This store is pre...|\n|NDhkzczKjLshODbqD...|_sS2LBIGNT5NQb6PD...|eC5evKn1TWDyHCyQA...|2013|    5| 28|  5.0|     0|    0|   0|I called WVM on t...|\n|T5fAqjjFooT4V0OeZ...|0AzLzHfOJgL7ROwhd...|SFQ1jcnGguO0LYWnb...|2010|    1|  8|  2.0|     1|    1|   1|I've stayed at ma...|\n|sjm_uUcQVxab_EeLC...|8zehGz9jnxPqXtOc7...|0kA0PAJ8QFMeveQWH...|2011|    7| 28|  4.0|     0|    0|   0|The food is alway...|\n|J4a2TuhDasjn2k3wW...|xGXzsc-hzam-VArK6...|RNm_RWkcd02Li2mKP...|2018|    1| 21|  1.0|     2|    0|   0|This place used t...|\n|28gGfkLs3igtjVy61...|EXOsmAB1s71WePlQk...|Q8c91v7luItVB0cMF...|2006|    4| 16|  2.0|     0|    0|   0|The setting is pe...|\n|9vqwvFCBG3FBiHGmO...|DbXHNl890xSXNiyRc...|XGkAG92TQ3MQUKGX9...|2017|   12|  2|  5.0|     0|    0|   0|Probably one of t...|\n|2l_TDrQ7p-5tANOyi...|mD-A9KOWADXvfrZfw...|LWUnzwK0ILquLLZcH...|2012|    5| 28|  4.0|     1|    0|   0|I am definitely a...|\n|KKVFopqzcVfcubIBx...|EEHhKSxUvJkoPSzeG...|99RsBrARhhx60UnAC...|2014|    5|  7|  5.0|     0|    0|   0|I work in the Pru...|\n+--------------------+--------------------+--------------------+----+-----+---+-----+------+-----+----+--------------------+\nonly showing top 10 rows\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "review.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "8635403"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 21
    }
   ],
   "source": [
    "review.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter review that in bussiness dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "business_id_set = set()\n",
    "for i in list(business.select('business_id').collect()):\n",
    "    business_id_set.add(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "8635403"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 23
    }
   ],
   "source": [
    "review.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "review = review.filter(review['business_id'].isin(business_id_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "605597"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 25
    }
   ],
   "source": [
    "review.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove reviews before 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "+----+-----+\n|year|count|\n+----+-----+\n|2004|    1|\n|2005|   72|\n|2006|  607|\n|2007| 3369|\n|2008| 8183|\n|2009|13023|\n|2010|20037|\n|2011|27092|\n|2012|30442|\n|2013|38252|\n|2014|52003|\n|2015|66122|\n|2016|69181|\n|2017|74100|\n|2018|80903|\n|2019|76977|\n|2020|42588|\n|2021| 2645|\n+----+-----+\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "review.groupBy('year').count().orderBy('year').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "review = review.filter(review.year>2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "560305"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 28
    }
   ],
   "source": [
    "review.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 :Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "+--------------------+\n|                text|\n+--------------------+\n|The ramen here is...|\n|\"Even the mad Cap...|\n|It's crazy how es...|\n|5 stars for the l...|\n|That was very gra...|\n+--------------------+\nonly showing top 5 rows\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "review.select(['text']).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Reviews Forsight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "neg_reviews = review.filter(review.stars <= 2.5)  # reviews with star <= 2.5\n",
    "# print(neg_reviews.count(), len(neg_reviews.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "+--------------------+--------------------+--------------------+----+-----+---+-----+------+-----+----+--------------------+\n|           review_id|         business_id|             user_id|year|month|day|stars|useful|funny|cool|                text|\n+--------------------+--------------------+--------------------+----+-----+---+-----+------+-----+----+--------------------+\n|EO5rALvJMkK8QEvUN...|9P-lp3AWDXGayDqJz...|u2xPfv6_wcKt-lW-C...|2018|    2| 11|  2.0|     0|    0|   0|The ramen here is...|\n|ggecU8oSt68aGEuiE...|7EbGTD7ZF30vEFBiH...|uQSBQI8hKuNRxyxhP...|2013|   10|  3|  2.0|     2|    0|   0|I don't remember ...|\n|UaxxixKaWiAL7_Oc_...|szCpLKuocAQnErkNi...|MrA1ib9jw_tw-uDzn...|2013|    8|  3|  2.0|     1|    0|   0|The renovation is...|\n|Q9Jh7uDqUYpM8aR3F...|ftc6tzrCBJVbuIi_y...|UNgMSeVC-Jk2q6ZhI...|2015|   10| 17|  1.0|     3|    0|   0|This pharmacy has...|\n|Q9qveSMALhyPZn7st...|Wv1A_nvyUuMEThZFu...|tI8Lve0J6JPklfUcJ...|2016|    6| 22|  2.0|     0|    0|   0|I actually love W...|\n+--------------------+--------------------+--------------------+----+-----+---+-----+------+-----+----+--------------------+\nonly showing top 5 rows\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "neg_reviews.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "+-------+-----+\n|   word|count|\n+-------+-----+\n|   food|70991|\n|  place|43913|\n|   like|42428|\n|service|39138|\n|   good|38361|\n|    one|36118|\n|    get|33493|\n|   time|33280|\n|   back|32405|\n|     us|31669|\n+-------+-----+\nonly showing top 10 rows\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from pyspark.ml.feature import CountVectorizer, StopWordsRemover, RegexTokenizer\n",
    "\n",
    "neg_reviews_text = neg_reviews.select(['text'])\n",
    "\n",
    "tokenizer = RegexTokenizer().setInputCol(\"text\").setOutputCol(\"words\").setPattern(\"\\\\W\")\n",
    "wordsData = tokenizer.transform(neg_reviews_text)\n",
    "\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "filter_data = remover.transform(wordsData)\n",
    "\n",
    "\n",
    "cv = CountVectorizer(inputCol='filtered', outputCol='vectors')\n",
    "model = cv.fit(filter_data)\n",
    "\n",
    "counts = model.transform(filter_data).select(['filtered','vectors'])\n",
    "\n",
    "neg_words_top10 = counts.select('vectors', explode(\"filtered\").alias(\"word\")).groupBy(\"word\").count()\n",
    "neg_words_top10 = neg_words_top10.sort(\"count\", ascending=False)\n",
    "neg_words_top10.show(10) # list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Remove non-informative words\n",
    "tokenizer = RegexTokenizer().setInputCol(\"text\").setOutputCol(\"words\").setPattern(\"\\\\W\")\n",
    "wordsData = tokenizer.transform(neg_reviews_text)\n",
    "\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "filter_data = remover.transform(wordsData)\n",
    "\n",
    "\n",
    "cv = CountVectorizer(inputCol='filtered', outputCol='vectors',minDF=2.0, vocabSize=1000)\n",
    "model = cv.fit(filter_data)\n",
    "\n",
    "counts = model.transform(filter_data).select(['filtered','vectors'])\n",
    "\n",
    "non_informative_words = ['food', 'place', 'like', 'service','good','one','get','time','back','us']\n",
    "\n",
    "neg_words_top150 = counts.select('vectors', explode(\"filtered\").alias(\"word\")).where(col(\"word\").isin(non_informative_words)==False).groupBy(\"word\").count()\n",
    "neg_words_top150 = neg_words_top150.sort(\"count\", ascending=False)\n",
    "neg_words_top150 = neg_words_top150.select(['word']).take(150) # list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "neg_words_top150_list = []\n",
    "for nwt150 in neg_words_top150:\n",
    "    if nwt150['word'].isnumeric():\n",
    "        continue\n",
    "    neg_words_top150_list.append(nwt150['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "['order', 'go', 'ordered', 'even', 'got', 'really', 'didn', 'never', 'said', 'minutes', 'came', 've', 'm', 'people', 'asked', 'restaurant', 'great', 'went', 'table', 'bad', 'two', 'better', 'first', 'also', 'told', 'way', 'chicken', 'know', 'much', 'going', 'wait', 'experience', 'bar', 'come', 'make', 'portland', 'staff', 'want', 'well', 'took', 'customer', 'menu', 'made', 'eat', 'another', 'wasn', 'take', 'ever', 'give', 'pizza', 'server', 're', 'say', 'still', 'nice', 'pretty', 'times', 'left', 'long', 'try', 'think', 'last', 'rude', 'sauce', 'hour', 'around', 'something', 'night', 'wanted', 'drinks', 'little', 'drink', 'right', 'day', 'nothing', 'coffee', 'see', 'sure', 'd', 'meal', 'taste', 'maybe', 'many', 'waiting', 'since', 'waitress', 'flavor', 'small', 'll', 'ok', 'salad', 'disappointed', 'cheese', 'tasted', 'won', 'away', 'waited', 'worst', 'customers', 'money', 'meat', 'thing', 'though', 'ask', 'location', 'next', 'line', 'new', 'tried', 'cold', 'half', 'quality', 'put', 'best', 'dinner', 'else', 'check', 'manager', 'price', 'anything', 'rice', 'always', 'walked', 'looked', 'terrible', 'finally', 'burger', 'love', 'let', 'however', 'review', 'business', 'called', 'someone', 'least', 'friend', 'beer', 'sandwich', 'worth', 'water', 'stars', 'person']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(neg_words_top150_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(-0.5, 399.5, 199.5, -0.5)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 36
    }
   ],
   "source": [
    "wordcloud_low = WordCloud(background_color=\"white\").generate(' '.join(neg_words_top150_list))\n",
    "plt.figure(figsize = (12,10))\n",
    "plt.imshow(wordcloud_low, interpolation='bilinear')\n",
    "plt.title('Word Cloud - Negative Yelp Restaurant Reviews', fontsize=16, y=1.01)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive Reviews Forsight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pos_reviews = review.filter(review.stars >= 4.5)  # reviews with star >= 4.5\n",
    "print(pos_reviews.count(), len(pos_reviews.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pos_reviews.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pos_reviews_text = pos_reviews.select(['text'])\n",
    "\n",
    "tokenizer = RegexTokenizer().setInputCol(\"text\").setOutputCol(\"words\").setPattern(\"\\\\W\")\n",
    "wordsData = tokenizer.transform(pos_reviews_text)\n",
    "\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "filter_data = remover.transform(wordsData)\n",
    "\n",
    "\n",
    "cv = CountVectorizer(inputCol='filtered', outputCol='vectors')\n",
    "model = cv.fit(filter_data)\n",
    "\n",
    "counts = model.transform(filter_data).select(['filtered','vectors'])\n",
    "\n",
    "pos_words_top10 = counts.select('vectors', explode(\"filtered\").alias(\"word\")).groupBy(\"word\").count()\n",
    "pos_words_top10 = pos_words_top10.sort(\"count\", ascending=False)\n",
    "pos_words_top10.show(10) # list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Remove non-informative words\n",
    "tokenizer = RegexTokenizer().setInputCol(\"text\").setOutputCol(\"words\").setPattern(\"\\\\W\")\n",
    "wordsData = tokenizer.transform(pos_reviews_text)\n",
    "\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "filter_data = remover.transform(wordsData)\n",
    "\n",
    "\n",
    "cv = CountVectorizer(inputCol='filtered', outputCol='vectors',minDF=2.0, vocabSize=1000)\n",
    "model = cv.fit(filter_data)\n",
    "\n",
    "counts = model.transform(filter_data).select(['filtered','vectors'])\n",
    "\n",
    "non_informative_words = ['food', 'place', 'like', 'service','portland','one']\n",
    "\n",
    "pos_words_top150 = counts.select('vectors', explode(\"filtered\").alias(\"word\")).where(col(\"word\").isin(non_informative_words)==False).groupBy(\"word\").count()\n",
    "pos_words_top150 = pos_words_top150.sort(\"count\", ascending=False)\n",
    "pos_words_top150 = pos_words_top150.select(['word']).take(150) # list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pos_words_top150_list = []\n",
    "for pwt150 in pos_words_top150:\n",
    "    if pwt150['word'].isnumeric():\n",
    "        continue\n",
    "    pos_words_top150_list.append(pwt150['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(pos_words_top150_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "wordcloud_low = WordCloud(background_color=\"white\").generate(' '.join(pos_words_top150_list))\n",
    "plt.figure(figsize = (12,10))\n",
    "plt.imshow(wordcloud_low, interpolation='bilinear')\n",
    "plt.title('Word Cloud - Positive Yelp Restaurant Reviews', fontsize=16, y=1.01)\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rich Features for Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from textblob import Word\n",
    "\n",
    "# review = review.withColumn('char_count', length(review['text']))\n",
    "\n",
    "# def cal_word_count(value):\n",
    "#     return len(value.split(\" \"))\n",
    "\n",
    "# udfcal_word_count = udf(cal_word_count, IntegerType())\n",
    "# review = review.withColumn(\"word_count\", lit(udfcal_word_count(\"text\")))\n",
    "\n",
    "# def cal_avg_word_len(value):\n",
    "#     words = value.split()\n",
    "#     word_sum = 0\n",
    "#     for word in words:\n",
    "#         word_sum += len(word)\n",
    "#     result = word_sum / len(words)\n",
    "#     return result\n",
    "\n",
    "# udfcal_avg_word_len = udf(cal_avg_word_len, DoubleType())\n",
    "# review = review.withColumn(\"avg_word_len\", lit(udfcal_avg_word_len(\"text\")))\n",
    "\n",
    "# def cal_stopword_count(value):\n",
    "#     words = value.split(\" \")\n",
    "#     spcount = 0\n",
    "#     for word in words:\n",
    "#         if word in stop_words:\n",
    "#             spcount += 1\n",
    "#     return spcount\n",
    "\n",
    "# udfcal_stopword_count = udf(cal_stopword_count, IntegerType())\n",
    "# review = review.withColumn(\"stopword_count\", lit(udfcal_stopword_count(\"text\")))\n",
    "\n",
    "# review.show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_cleaned_text(value):\n",
    "    words = re.split(\"(?:[^a-zA-Z']+)\", value.lower())\n",
    "    result = \" \"\n",
    "    result = result.join(Word(w.lower()).lemmatize() for w in words if w.lower() not in stop_words)\n",
    "    return result\n",
    "\n",
    "udfget_cleaned_text = udf(get_cleaned_text, StringType())\n",
    "review = review.withColumn(\"cleaned_text\", lit(udfget_cleaned_text(\"text\")))\n",
    "\n",
    "# review.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "review.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Add column 'polarity' and 'subjectivity'\n",
    "from textblob import TextBlob\n",
    "\n",
    "def cal_polarity(value):\n",
    "    return TextBlob(value).sentiment[0]\n",
    "\n",
    "udfcal_polarity = udf(cal_polarity, DoubleType())\n",
    "review = review.withColumn(\"polarity\", lit(udfcal_polarity(\"cleaned_text\")))\n",
    "\n",
    "def cal_subjectivity(value):\n",
    "    return TextBlob(value).sentiment[1]\n",
    "\n",
    "udfcal_subjectivity = udf(cal_subjectivity, DoubleType())\n",
    "review = review.withColumn(\"subjectivity\", lit(udfcal_subjectivity(\"cleaned_text\")))\n",
    "\n",
    "# review.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Calculate Vader Sentiment Analysis Scores\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# test = analyzer.polarity_scores(\"The ramen here is less than great. It came out luke warm and oily. The service we received was NOT good. I will not be returning.\")\n",
    "\n",
    "# print(test)\n",
    "\n",
    "def cal_compound(value):\n",
    "    return analyzer.polarity_scores(value)['compound']\n",
    "\n",
    "udfcal_compound = udf(cal_compound, DoubleType())\n",
    "review = review.withColumn(\"compound\", lit(udfcal_compound(\"text\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vader Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# def cal_neg(value):\n",
    "#     return analyzer.polarity_scores(value)['neg']\n",
    "\n",
    "# udfcal_neg = udf(cal_neg, DoubleType())\n",
    "# review = review.withColumn(\"neg\", lit(udfcal_neg(\"text\")))\n",
    "\n",
    "# def cal_neu(value):\n",
    "#     return analyzer.polarity_scores(value)['neu']\n",
    "\n",
    "# udfcal_neu = udf(cal_neu, DoubleType())\n",
    "# review = review.withColumn(\"neu\", lit(udfcal_neu(\"text\")))\n",
    "\n",
    "# def cal_pos(value):\n",
    "#     return analyzer.polarity_scores(value)['pos']\n",
    "\n",
    "# udfcal_pos = udf(cal_pos, DoubleType())\n",
    "# review = review.withColumn(\"pos\", lit(udfcal_pos(\"text\")))\n",
    "\n",
    "review.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "review.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(review.count(), len(review.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "dropped_review = review.filter(review.polarity == 0.0)\n",
    "dropped_review = dropped_review.filter(dropped_review.subjectivity == 0.0)\n",
    "dropped_review = dropped_review.filter(dropped_review.compound == 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "dropped_id_set = set()\n",
    "for i in list(dropped_review.select('review_id').collect()):\n",
    "    dropped_id_set.add(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(len(dropped_id_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "combined_review = review.filter(review['review_id'].isin(dropped_id_set) == False)\n",
    "combined_review = combined_review.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(combined_review.count()) # 559334 + 971 = 560305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "combined_review.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "dropped_review = dropped_review.dropna()\n",
    "dropped_review = dropped_review.select(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "dropped_review.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(dropped_review.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "combined_review.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Topic Modeling\n",
    "from pyspark.sql import SQLContext, Row\n",
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from pyspark.mllib.linalg import Vector, Vectors\n",
    "from pyspark.ml.feature import CountVectorizer, StopWordsRemover, RegexTokenizer\n",
    "\n",
    "tp_reviews = combined_review.select(['text'])\n",
    "\n",
    "tokenizer = RegexTokenizer().setInputCol(\"text\").setOutputCol(\"words\").setPattern(\"\\\\W\")\n",
    "wordsData = tokenizer.transform(tp_reviews)\n",
    "\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "filter_data = remover.transform(wordsData)\n",
    "\n",
    "\n",
    "cv = CountVectorizer(inputCol='filtered', outputCol='vectors',minDF=2.0, vocabSize=1000)\n",
    "model = cv.fit(filter_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "result = model.transform(filter_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "result = result.select(\"*\").withColumn(\"id\", monotonically_increasing_id())\n",
    "result.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "result = result.repartition(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IDF\n",
    "idf = IDF(inputCol=\"vectors\", outputCol=\"features\")\n",
    "idfModel = idf.fit(result)\n",
    "result_tfidf = idfModel.transform(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "corpus = result.select(['id','vectors']).rdd.map(lambda x: [x[0],Vectors.fromML(x[1])]).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ldaModel = LDA.train(corpus, k=7,maxIterations=50,optimizer='online')\n",
    "topics = ldaModel.topicsMatrix()\n",
    "vocabArray = model.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "wordNumbers = 10  # number of words per topic\n",
    "topicIndices = spark.sparkContext.parallelize(ldaModel.describeTopics(maxTermsPerTopic = wordNumbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def topic_render(topic):  # specify vector id of words to actual words\n",
    "    terms = topic[0]\n",
    "    result = []\n",
    "    for i in range(wordNumbers):\n",
    "        term = vocabArray[terms[i]]\n",
    "        result.append(term)\n",
    "    return result\n",
    "\n",
    "topics_final = topicIndices.map(lambda topic: topic_render(topic)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for topic in range(len(topics_final)):\n",
    "    print (\"Topic\" + str(topic) + \":\")\n",
    "    for term in topics_final[topic]:\n",
    "        print (term)\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "fig, axes = plt.subplots(7, 1, figsize=(20,20), sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    fig.add_subplot(ax)\n",
    "    topic_words = topics_final[i]\n",
    "    wordcloud_low = WordCloud(background_color=\"white\").generate(' '.join(topic_words))\n",
    "    plt.gca().imshow(wordcloud_low)\n",
    "    plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.axis('off')\n",
    "plt.margins(x=5, y=5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import LDA\n",
    "\n",
    "dataset = result.select(['text','vectors'])\n",
    "\n",
    "mllda = LDA(featuresCol=\"vectors\",k=7, maxIter=20)\n",
    "mlmodel = mllda.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Describe topics.\n",
    "topics = mlmodel.describeTopics()\n",
    "topics.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter \n",
    "key_topics = [[] for _ in range(7)]\n",
    "\n",
    "for i in topics['topic','termIndices'].collect():\n",
    "    key_topics[i['topic']] = list(itemgetter(*i['termIndices'])(model.vocabulary))\n",
    "\n",
    "print(key_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Shows the result\n",
    "transformed = mlmodel.transform(dataset)\n",
    "transformed.show(3,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "transformed = mlmodel.transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "transformed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import vector_to_array\n",
    "transformed = transformed.withColumn(\"topicDistribution\", vector_to_array(\"topicDistribution\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "transformed = transformed.drop('vectors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "transformed = transformed.drop('topicDistribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def tran_keywords(value):\n",
    "    max_index = int(np.argmax(value))\n",
    "    return key_topics[max_index]\n",
    "\n",
    "udftran_keywords = udf(tran_keywords, ArrayType(StringType()))\n",
    "transformed = transformed.withColumn(\"Keywords\", lit(udftran_keywords(\"topicDistribution\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "transformed.show(2,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "final_review = combined_review.join(transformed, combined_review.text == transformed.text, 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "final_review = final_review.drop('text')\n",
    "final_review = final_review.drop('year')\n",
    "final_review = final_review.drop('month')\n",
    "final_review = final_review.drop('day')\n",
    "final_review = final_review.drop('useful')\n",
    "final_review = final_review.drop('funny')\n",
    "final_review = final_review.drop('cool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "final_review.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "path = 'yelp_academic_dataset_user.json'\n",
    "user = spark.read.json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "user.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "user_col = ['user_id','name','review_count','yelping_since','friends','useful','funny','cool','fans','average_stars']\n",
    "user = user.select(user_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "user.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# get active user\n",
    "user = user[user.review_count>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "user.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# col = ['business_id','name','city','state','stars','review_count','categories','latitude','longitude','is_open', 'postal_code']\n",
    "# city = ['Portland']\n",
    "# category =  ['Restaurants','Food','Coffee & Tea','Sandwiches','Breakfast & Brunch']\n",
    "# is_open = 1\n",
    "business_df = business.toPandas()\n",
    "business_df.to_csv('business.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# col = ['review_id','business_id','user_id','year','month','day','stars','useful','funny','cool','text']\n",
    "# only include reviews which \"business_id\" in \"bussiness.json\"\n",
    "review_df = review.toPandas()\n",
    "review_df.to_csv('review.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# col = ['user_id','name','review_count','yelping_since','friends','useful','funny','cool','fans','average_stars']\n",
    "user_df = user.toPandas()\n",
    "user_df.to_csv('user.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-cb58f220",
   "language": "python",
   "display_name": "PyCharm (Final)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}