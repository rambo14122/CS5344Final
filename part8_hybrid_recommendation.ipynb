{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Part 8 Hybrid Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "    .config(\"spark.driver.memory\", \"32g\")\\\n",
    "    .config(\"spark.executor.memory\",\"32g\")\\\n",
    "    .config(\"spark.driver.maxResultSize\",\"0\")\\\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\",\"-1\")\\\n",
    "    .config(\"spark.sql.broadcastTimeout\",\"1200\")\\\n",
    "    .config(\"spark.default.parallelism\", \"32\")\\\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"3600\")\\\n",
    "    .config(\"spark.local.dir\",\"D:\\\\Data\")\\\n",
    "    .appName(\"part8\").getOrCreate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "review = spark.read.csv(\"part4_topicmodeling_review.csv\", header=True, multiLine=True)\n",
    "business = spark.read.csv(\"part1_dataclean_business.csv\",header=True, multiLine=True)\n",
    "user = spark.read.csv(\"part1_dataclean_user.csv\", header=True, multiLine=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# define utility functions\n",
    "\n",
    "def cosine_similarity(vector1, vector2): \n",
    "    return np.dot(vector1, vector2) / np.sqrt(np.dot(vector1, vector1)) / np.sqrt(np.dot(vector2, vector2)) "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare Content Based Filtering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "+--------------------+--------------------+\n|         business_id|         word_vector|\n+--------------------+--------------------+\n|0OLouFEhEm3pIh4Sx...|[0.00706271847664...|\n|M4zae56hA6sb6V2Ty...|[-0.0525487022407...|\n|W60O4ast9uAq03n7n...|[-0.0027295319850...|\n+--------------------+--------------------+\nonly showing top 3 rows\n\n",
      "[-0.05254870224070885,0.03538502551234829,-0.03854379182152756,-0.053777138675465165,0.11863246697258918,-0.042976504449101866,-0.06302669620455528,-0.010523899725802371,-0.05600440347677558,-0.051089978157957947,-0.12485574790768786,-0.01871904768133106,-0.01511064755262284,-0.012473998580663153,-0.0065393127728708925,-0.018541000201754955,0.026146981704871602,-0.0016333255095140166,0.019860426191859133,-0.02298519021158624,-0.06866251518718708,-0.04173724704121691,0.058374670250007615,-0.033756228102148386,0.036534135101342076,0.031458382954585626,0.014802017625441538,0.04208449111690074,0.05030599064622714,0.02105374494679037,-0.0195642894819269,0.0034160628788665777,0.03395830864219333,0.01141115462098575,-0.07339074955288873,0.006038148350013599,0.030040749926342647,0.019178156645195826,0.030420070933069077,0.026424276935886563,0.06978567937052522,-0.038662586510325364,-0.003517041154072199,-0.0709566290981172,0.030881129774067616,0.03637652215834272,-0.042959994960077935,0.04972426530825177,0.05291908217583924,-0.007215156437148692,-0.06759938494600379,0.03604435021378773,0.026383831714969518,0.02697421875927038,-0.08937993100696903,-0.0675996710759407,-0.01982851261380241,-0.0017940402937706883,-0.058421112945044956,-0.08880331134560483,-0.005576195163382579,0.016750543706828425,0.014313391662452303,0.04417082428150613,0.006844726232884172,-0.07906391895275204,-0.04351495841047669,0.022416933752259262,-0.021910484226283663,-0.10473319522737395,-0.054996799571903864,-0.014218603449948854,-0.006363870307356984,-0.06445056761510565,0.022793586533658077,-0.06624891750990053,0.04677990500011084,0.04364684822155727,-0.029078167441544234,0.08173745354319949,0.04290179008066342,-0.035191017495432055,0.009587641693031453,-0.02862967071102764,0.01855057649868083,0.003869431405685691,0.0037144745455932587,-0.06723655056475496,0.05858744996030741,0.019736421721136845,-0.03625163426473645,-0.005349039772723941,-0.006491014786744817,-0.0841400456261289,-0.03875898864991421,0.0557050942813113,-0.08074009112186684,-0.06281409859545732,0.08900172704076087,-0.017272912181610128]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# load pipeline model\n",
    "\n",
    "pipeline_model = PipelineModel.load(\"content_based_pipeline_model\")\n",
    "\n",
    "\n",
    "# load all business vectors\n",
    "\n",
    "all_business_vectors_df = spark.read.load(\"part5_all_business_vectors.parquet\")\n",
    "all_business_vectors_df.show(3)\n",
    "\n",
    "all_business_vectors = all_business_vectors_df.rdd.map(lambda x: (x[0], x[1])).collect()\n",
    "print(all_business_vectors[1][1])\n",
    "\n",
    "def get_similar_business(business_ids, limit=10):\n",
    "    schema = StructType([   \n",
    "                            StructField(\"business_id\", StringType(), True),\n",
    "                            StructField(\"score\", IntegerType(), True)\n",
    "                        ])\n",
    "    similar_businesses_df = spark.createDataFrame([], schema)\n",
    "    \n",
    "    for b_id in business_ids:\n",
    "        try:\n",
    "            input_vec = [(r[1]) for r in all_business_vectors if r[0] == b_id][0]\n",
    "        except:\n",
    "            continue\n",
    "        similar_business_rdd = spark.sparkContext.parallelize(\n",
    "            (i[0], float(cosine_similarity(input_vec, i[1]))) for i in all_business_vectors)\n",
    "\n",
    "        similar_business_df = spark.createDataFrame(similar_business_rdd) \\\n",
    "            .withColumnRenamed(\"_1\", \"business_id\") \\\n",
    "            .withColumnRenamed(\"_2\", \"score\") \\\n",
    "            .orderBy(\"score\", ascending = False)\n",
    "            \n",
    "        similar_business_df = similar_business_df.filter(col(\"business_id\") != b_id).limit(limit)\n",
    "        similar_businesses_df = similar_businesses_df \\\n",
    "                                    .union(similar_business_df)\n",
    "    return similar_businesses_df.orderBy(\"score\", ascending=False).limit(limit)\n",
    "\n",
    "def get_user_recommendation(user_id, limit = 10):\n",
    "    print(f\"[content based filtering] user id: {user}\")\n",
    "    user_reviewed_businesses = review.filter((col(\"user_id\") == user_id) & (col(\"superscore\")>=3.0))\\\n",
    "        .sample(False, 0.5).limit(5).select(\"business_id\")\n",
    "    business_ids = [i.business_id for i in user_reviewed_businesses.collect()]\n",
    "    print(f\"[content based filtering] user reviewed businesses: {business_ids}\")\n",
    "    return content_based_get_details(get_similar_business(business_ids, limit))\n",
    "\n",
    "def get_keywords_recommendation(keywords, limit=10):\n",
    "    \n",
    "    print(f\"[content based filtering] keywords: {keywords}\")\n",
    "    keywords_df = spark.sparkContext.parallelize([(0, keywords)]).toDF([\"business_id\", \"text\"])\n",
    "    \n",
    "    # transform the the keywords to vectors\n",
    "    \n",
    "    transformed_keywords_df = pipeline_model.transform(keywords_df)    \n",
    "    keywords_vector = transformed_keywords_df.select(\"word_vector\").collect()[0][0]\n",
    "    sim_bus_byword_rdd = spark.sparkContext\\\n",
    "        .parallelize((i[0], float(cosine_similarity(keywords_vector, i[1]))) for i in all_business_vectors)\n",
    "\n",
    "    sim_bus_byword_df = spark.createDataFrame(sim_bus_byword_rdd) \\\n",
    "         .withColumnRenamed(\"_1\", \"business_id\") \\\n",
    "         .withColumnRenamed(\"_2\", \"score\") \\\n",
    "         .orderBy(\"score\", ascending = False) \\\n",
    "         .limit(limit)\n",
    "    \n",
    "    # return top 10 similar businesses\n",
    "    \n",
    "    a = sim_bus_byword_df.limit(limit)\n",
    "    return content_based_get_details(a)\n",
    "\n",
    "def content_based_get_details(recommended_business):\n",
    "    return recommended_business.join(business, \"business_id\", \"inner\").orderBy(\"score\", ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# verify the loading process for content based\n",
    "# test case 1\n",
    "\n",
    "content_based_get_details(\n",
    "    get_similar_business([\"Npm0cjoyWwyV13OULL9qOA\", \"ZKPqinA-7gkDA8-yzubSYw\"]))\\\n",
    "    .toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test case 2\n",
    "\n",
    "get_user_recommendation(\"uLhdaZUsVvT0gbNTdOSzDg\").toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test case 3\n",
    "\n",
    "get_keywords_recommendation(\"burger\").toPandas()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare Collaborative Filtering "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loaded_user_recommendations = spark.read.load(\"part6_all_user_recommendations.parquet\").cache()\n",
    "loaded_user_recommendations.show(3)\n",
    "loaded_user_recommendations.printSchema()\n",
    "\n",
    "business_new_df = spark.read.load(\"part6_business_with_index.parquet\")\n",
    "business_new_df.show(2)\n",
    "\n",
    "def get_collaborative_recommendation(user_id):\n",
    "\n",
    "    recommended_business =  spark.createDataFrame(\n",
    "        loaded_user_recommendations.filter(col(\"user_id\") == user_id)\n",
    "                                                  .rdd.flatMap(lambda p: p[1]))\n",
    "    return business_new_df.join(recommended_business, \"business_index\", \"inner\")\\\n",
    "             .orderBy(\"rating\", ascending = False)\n",
    "\n",
    "random_user = loaded_user_recommendations.sample(0.01, seed=1).head(1)[0].user_id\n",
    "print(f\"[collaborative filtering] test user id: {random_user}\")\n",
    "get_collaborative_recommendation(random_user).toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare Friend Recommendation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_friends = user.select(\"user_id\", \"friends\")\n",
    "\n",
    "def get_friends_recommendation(user_id, limit=10):\n",
    "    friends = user_friends.filter(col(\"user_id\")==user_id).limit(1)\n",
    "    if friends.count()<1:\n",
    "        return None\n",
    "    friend_str = friends.select(\"friends\").rdd.collect()[0][0].replace(\" \", \"\")\n",
    "    if friend_str==\"\":\n",
    "        return None\n",
    "    friend_list = list(friend_str.split(\",\"))\n",
    "    friends_businesses = review.filter(\n",
    "         (col(\"superscore\")>=3.0) &(col(\"user_id\").isin(friend_list)))\\\n",
    "        .orderBy(\"superscore\", ascending=False)\\\n",
    "        .select(\"business_id\").distinct().limit(limit).rdd.collect()\n",
    "    if len(friends_businesses)==0:\n",
    "        return None\n",
    "    business_list = []\n",
    "    for row in friends_businesses:\n",
    "        business_list.append(row.business_id)\n",
    "    return get_business_details(business_list) \n",
    "\n",
    "def get_business_details(business_list):\n",
    "    return business.filter(col(\"business_id\").isin(business_list)).orderBy(\"stars\", ascending=False)\n",
    "get_friends_recommendation(\"uLhdaZUsVvT0gbNTdOSzDg\").toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-cb58f220",
   "language": "python",
   "display_name": "PyCharm (Final)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}